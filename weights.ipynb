{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49f7ce6-152b-4cb6-84b2-6aeb13b60c3d",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd27f29-8862-40fc-9c7d-8875dcdfbe3a",
   "metadata": {},
   "source": [
    "### ANS 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc622bda-9c58-4284-994a-650af460a034",
   "metadata": {},
   "source": [
    "Weight intialization are important becuase we updates the weights to obtain minimum loss so by chossing appropraite weight we can fast the process and to avoid vanishing gradient if the weights are too small then it can lead to slow weight update if the weights are too much then it can cause instability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d42b4-2da2-4b75-8d65-b41b075a4d91",
   "metadata": {},
   "source": [
    "### ANS 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aed6f2-200e-459a-9ee6-cae9d7ddeece",
   "metadata": {},
   "source": [
    "Challanges asoociated with improper weight initialization:\n",
    "1) it can lead vanishing gradient problem\n",
    "2) it can lead to more time complexcity \n",
    "3) it can lead to same weight updation for each neuron resulting in not learning about the complexcity of the model.\n",
    "***\n",
    "it can affect the model:\n",
    "1) it will more time for the weight updation.\n",
    "2) for certain epochs we may not get the desired result.\n",
    "3) it can also increases computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301e579-025f-43ab-a8ed-e32d95ea02ae",
   "metadata": {},
   "source": [
    "### ANS 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea702c-4f4b-42ba-9b80-e2ec50c74a9a",
   "metadata": {},
   "source": [
    "variance is the spread of the data.Variance is realted to the weight initialization due to the following reasons:\n",
    "1) if varince is low then it can in result gradient vanishing means it difference between old weight and new weight will be low.\n",
    "2) if the variance is high then it can result in instablity in the weights updation \n",
    "***\n",
    "because of the upper reasons it is necessary to consider the varince of the weights during intialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4a568-a3ee-43d3-9f10-b7f88d0367f3",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6b17e-ef31-4523-ae2c-cd2ad80c406c",
   "metadata": {},
   "source": [
    "### ANS 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab746d5b-2442-426f-887d-e7aa4ffa8da4",
   "metadata": {},
   "source": [
    "Zero intialization is the technique of weights intialization. zero intialization means making all the weights zero. Potential limitation is if all neurons have zero weights they will end up learning the same feature during training and updates all weights same irrespective of diverse feature.\n",
    "***\n",
    "it can be appropriate to use when we want to update the weights same for all neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f512b4c-b628-4483-9809-49836db05097",
   "metadata": {},
   "source": [
    "### ANS 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10976cbd-4e2f-4feb-a494-dab0f82f04fe",
   "metadata": {},
   "source": [
    "random intialization is the weight intialization technique in this technique we intialize weights randomly. we can solve the potential issues like saturation or vanishing gradient by selection random weights not too high or no too low, meaning by selecting medium range weights we can solve the saturation oe vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe22e7a-c8b1-4b74-9f83-f092fb300857",
   "metadata": {},
   "source": [
    "### ANS 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2af465-0fb8-4614-86b5-f3100447e507",
   "metadata": {},
   "source": [
    "Xavier/Grodat intialization is a weight intialization technique which have a standard of devaition=2/fin+fout for normal distribution, and for uniform distribution standard deviation is sqrt(6/fin+fout),sqrt(6/fin+fout). it is used when we use tanh activation function.\n",
    "***\n",
    "it addresses the challanges of improper weights problem by selecting appropraite weights. as it selects the weights of defined variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a0c99-dba0-42e2-b4f9-5f5329a163ec",
   "metadata": {},
   "source": [
    "### ANS 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178089a4-4549-4cff-a204-6be31b2226d6",
   "metadata": {},
   "source": [
    "He intialization is the weight intialization technique which have varince of 2/fin for normal distribution of data, for uniform distribution varince is (-6/fin,+6/fin). He intialization is specifically used when activation is relu. it differ from xavier intialization as it have different varaince and both are used for different activation function. He is preferred when we use relu activation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56db16-36b7-4c88-bcc0-d8e676f6d5e3",
   "metadata": {},
   "source": [
    "# PART 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e579037-1ff3-4a5c-9e8e-7e64ea104735",
   "metadata": {},
   "source": [
    "### ANS 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61edc92d-55f3-4b11-9cad-faa4d8cd24ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import time \n",
    "%load_ext tensorboard\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5003fe48-ef9f-4342-9a47-e7e1ff5689e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train_full,y_train_full),(X_test,y_test)=tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full=X_train_full/255.0\n",
    "X_test=X_test/255.0\n",
    "X_valid,X_train=X_train_full[:5000],X_train_full[5000:]\n",
    "y_valid,y_train=y_train_full[:5000],y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ad0fc-db1a-47c1-9d89-68264ee955b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### HE intialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30388530-e068-4a9f-be3d-800e4369eb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAYERS=[tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "        tf.keras.layers.Dense(300,activation='relu',kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dense(100,activation='relu',kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dense(10,activation='softmax')\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73bb0080-beab-4b03-a18b-4373e2b2a2a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c9af11-f3ac-447c-9076-1cc2141421fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46bfe46d-61ce-4c1a-99a0-58e1b8a1184e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\amand\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\amand\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1719/1719 - 3s - loss: 0.6977 - accuracy: 0.7694 - val_loss: 0.4948 - val_accuracy: 0.8344 - 3s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 2s - loss: 0.4800 - accuracy: 0.8339 - val_loss: 0.4496 - val_accuracy: 0.8496 - 2s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 2s - loss: 0.4357 - accuracy: 0.8479 - val_loss: 0.4120 - val_accuracy: 0.8582 - 2s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 2s - loss: 0.4082 - accuracy: 0.8565 - val_loss: 0.3893 - val_accuracy: 0.8682 - 2s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 2s - loss: 0.3881 - accuracy: 0.8642 - val_loss: 0.3686 - val_accuracy: 0.8744 - 2s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 2s - loss: 0.3735 - accuracy: 0.8699 - val_loss: 0.3919 - val_accuracy: 0.8650 - 2s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 3s - loss: 0.3599 - accuracy: 0.8735 - val_loss: 0.3779 - val_accuracy: 0.8662 - 3s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 2s - loss: 0.3477 - accuracy: 0.8778 - val_loss: 0.3496 - val_accuracy: 0.8746 - 2s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 2s - loss: 0.3369 - accuracy: 0.8803 - val_loss: 0.3563 - val_accuracy: 0.8720 - 2s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 2s - loss: 0.3270 - accuracy: 0.8843 - val_loss: 0.3345 - val_accuracy: 0.8814 - 2s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=10,validation_data=(X_valid,y_valid), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e79077-6a32-4a5c-b08a-19ab015f18f7",
   "metadata": {},
   "source": [
    "### Xavier intialzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37501903-98c1-4a63-bd22-6f7395dde24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAYERS=[tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "        tf.keras.layers.Dense(300,activation='tanh',kernel_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dense(100,activation='tanh',kernel_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dense(10,activation='softmax')\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeaddd97-1451-4aa7-9521-612b9467408c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 2s - loss: 0.3194 - accuracy: 0.8862 - val_loss: 0.3420 - val_accuracy: 0.8806 - 2s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 2s - loss: 0.3118 - accuracy: 0.8887 - val_loss: 0.3262 - val_accuracy: 0.8854 - 2s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 2s - loss: 0.3044 - accuracy: 0.8911 - val_loss: 0.3333 - val_accuracy: 0.8804 - 2s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 2s - loss: 0.2972 - accuracy: 0.8935 - val_loss: 0.3202 - val_accuracy: 0.8870 - 2s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 2s - loss: 0.2918 - accuracy: 0.8960 - val_loss: 0.3222 - val_accuracy: 0.8856 - 2s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 2s - loss: 0.2858 - accuracy: 0.8967 - val_loss: 0.3126 - val_accuracy: 0.8860 - 2s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 2s - loss: 0.2795 - accuracy: 0.9003 - val_loss: 0.3142 - val_accuracy: 0.8860 - 2s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 2s - loss: 0.2735 - accuracy: 0.9016 - val_loss: 0.3065 - val_accuracy: 0.8886 - 2s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 2s - loss: 0.2690 - accuracy: 0.9024 - val_loss: 0.3088 - val_accuracy: 0.8896 - 2s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 2s - loss: 0.2637 - accuracy: 0.9042 - val_loss: 0.3165 - val_accuracy: 0.8850 - 2s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=10,validation_data=(X_valid,y_valid), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ad48e-adc4-4254-8c6c-017f0778105f",
   "metadata": {},
   "source": [
    "### random intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cffa043-69a2-47cb-9046-7a84f36ac5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAYERS=[tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "        tf.keras.layers.Dense(300,activation='tanh',kernel_initializer='random_normal'),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dense(100,activation='tanh',kernel_initializer='random_normal'),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dense(10,activation='softmax')\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3235f737-1f07-44cf-9bf8-673df9d56eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 2s - loss: 0.2589 - accuracy: 0.9067 - val_loss: 0.3207 - val_accuracy: 0.8802 - 2s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 2s - loss: 0.2544 - accuracy: 0.9096 - val_loss: 0.2967 - val_accuracy: 0.8932 - 2s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 2s - loss: 0.2497 - accuracy: 0.9094 - val_loss: 0.3119 - val_accuracy: 0.8868 - 2s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 2s - loss: 0.2458 - accuracy: 0.9115 - val_loss: 0.3263 - val_accuracy: 0.8828 - 2s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 2s - loss: 0.2410 - accuracy: 0.9138 - val_loss: 0.2933 - val_accuracy: 0.8944 - 2s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 2s - loss: 0.2368 - accuracy: 0.9151 - val_loss: 0.3066 - val_accuracy: 0.8892 - 2s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 2s - loss: 0.2333 - accuracy: 0.9164 - val_loss: 0.2959 - val_accuracy: 0.8926 - 2s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 2s - loss: 0.2302 - accuracy: 0.9167 - val_loss: 0.2997 - val_accuracy: 0.8940 - 2s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 2s - loss: 0.2259 - accuracy: 0.9188 - val_loss: 0.2932 - val_accuracy: 0.8930 - 2s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 2s - loss: 0.2221 - accuracy: 0.9203 - val_loss: 0.2922 - val_accuracy: 0.8946 - 2s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=10,validation_data=(X_valid,y_valid), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2894df-b72f-4e62-87f1-7ceba2828837",
   "metadata": {},
   "source": [
    "### Zero intialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80302ffd-d7e2-426e-95e6-b5d8fedc1150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAYERS=[tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "        tf.keras.layers.Dense(300,activation='tanh',kernel_initializer='zero'),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dense(100,activation='tanh',kernel_initializer='zero'),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dense(10,activation='softmax')\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92b99d53-9065-40fd-b61a-c205d3ca051b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 3s - loss: 0.2180 - accuracy: 0.9216 - val_loss: 0.2993 - val_accuracy: 0.8880 - 3s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 2s - loss: 0.2151 - accuracy: 0.9222 - val_loss: 0.2898 - val_accuracy: 0.8980 - 2s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 2s - loss: 0.2108 - accuracy: 0.9245 - val_loss: 0.3051 - val_accuracy: 0.8902 - 2s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 2s - loss: 0.2085 - accuracy: 0.9247 - val_loss: 0.2975 - val_accuracy: 0.8912 - 2s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 2s - loss: 0.2047 - accuracy: 0.9273 - val_loss: 0.2933 - val_accuracy: 0.8918 - 2s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 2s - loss: 0.2019 - accuracy: 0.9279 - val_loss: 0.2997 - val_accuracy: 0.8922 - 2s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 2s - loss: 0.1986 - accuracy: 0.9288 - val_loss: 0.2892 - val_accuracy: 0.8958 - 2s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 2s - loss: 0.1943 - accuracy: 0.9306 - val_loss: 0.3103 - val_accuracy: 0.8916 - 2s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 2s - loss: 0.1914 - accuracy: 0.9316 - val_loss: 0.2967 - val_accuracy: 0.8934 - 2s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 3s - loss: 0.1892 - accuracy: 0.9312 - val_loss: 0.2979 - val_accuracy: 0.8938 - 3s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=10,validation_data=(X_valid,y_valid), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526c547-7afa-4d54-8c00-3bf61d0f144c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ANS 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2752b-6873-4f7b-8a1e-076953ca495b",
   "metadata": {},
   "source": [
    "Zero intialization: it is not usually but in some casses when we have non-learnalbe parameter that a spefici layer that should not be trained. it intializes the weights zero.\n",
    "***\n",
    "Xavier intialization: it intializes the weights of a specific varaince and it is used with tanh activation function.\n",
    "***\n",
    "He intialization: it intializes the weights of a specific varaince and it is used with relu activation function.\n",
    "***\n",
    "random_intialization= it randomly intialzes the weights the weights can be higher or smaller. but using medium range can lower the problem of gradiend vanishing and "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
