{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791f13b4",
   "metadata": {},
   "source": [
    "### ANS 1\n",
    "projection is the dot product of point p1 and vector which gives the scalar value. it is used in pca to calcuate the varaince and whichever pca has greater varaince that pca is selected as pc1,pc2_ _ _. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1603d",
   "metadata": {},
   "source": [
    "### ANS 4 \n",
    "choice of principle components impact the performace as if we select low pricniple component it may cover less varaince and can lead to underfit.If we select the higher number of principle component it may result in overifitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa9448",
   "metadata": {},
   "source": [
    "### ANS 5\n",
    "PCA is used for feature extraction. In feature selection important feature get selected and we neglect the varaince and spread of the other feature. But in pca every feautre varaince and spread get calculated which leads to better approach. if there are n feature there will be n pca and all pca are arranged in ascending order(based on the varaince). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe8393",
   "metadata": {},
   "source": [
    "### ANS 7\n",
    "relationship between spread and varaince.\n",
    "spread is the extent or distribution of the data point in a dataset.it tells us how data points are spread out in the space. variance is the average squared devation of each data point from the mean.spread is the distribution while varince is the numerical measure of distribution.In PCa principle components are derived in such a way that first priciple component capture high varince.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc81c0",
   "metadata": {},
   "source": [
    "### ANS 8\n",
    "1) first covarince matrix is calculated.  \n",
    "2) then we apply linear transofrmation.\n",
    "3) based on the linear transformation we get eigen vector.\n",
    "4) then we apply formula to calculate the eigen value.\n",
    "5) the highest eigen value vecter is selected as first principle component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa5eb80",
   "metadata": {},
   "source": [
    "### ANS 3\n",
    "covaraince matrix is used to find the eigen vector by applying linear transformation. covarince vector is decomposed into its eigen vector and eigen value. eigen decomposition is performed on covariance matrix to find eigenvector and eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd04c7",
   "metadata": {},
   "source": [
    "### ANS 9\n",
    "to handle data with high varince in some dimension but low in other varince in other we can use standaradization or normalization. PCA identifies the principle components based on the variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15519af7",
   "metadata": {},
   "source": [
    "### ANS 2\n",
    "1) first covarince matrix is calculated.  \n",
    "2) then we apply linear transofrmation.\n",
    "3) based on the linear transformation we get eigen vector.\n",
    "4) then we apply formula to calculate the eigen value.\n",
    "5) the highest eigen value vecter is selected as first principle component.\n",
    "***\n",
    "the whole point of pca is to reduce the dimesionlaity of the dataset by projecting it into new space defined by principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7daccc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
