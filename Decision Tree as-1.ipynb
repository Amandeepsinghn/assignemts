{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1a6fdc",
   "metadata": {},
   "source": [
    "### ANS 1\n",
    "decision tree classifier is used to make model when we have  classificaiton dependent varaible it alogritihim is \n",
    "1) it makes the tree of all feature and make leaf node according to the result of impurity there are two ways to calculate the impurity ginni purity(when dataset is huge) and entropy(when dataset is small).\n",
    "2) we make root node feature based on the value of inforamtion gain of every feature. feature which have the highest information gain we make that feature root node.\n",
    "3) to make model such that it not overfit we use pre and post pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278b90c",
   "metadata": {},
   "source": [
    "### ANS 2\n",
    "step by step explanation of mathematical intution(pre prunning):\n",
    "1) first we split the data \n",
    "2) then we make make the model DecisonTreeClassifier() \n",
    "3) using gridSearchCV we select the hyperparameter \n",
    "4) using gridseacrh we fit our x_train and y_train \n",
    "5) the we predict the y value on the X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c60869",
   "metadata": {},
   "source": [
    "### ANS 3 \n",
    "decision tree classifier is used to solve binary classification problem:\n",
    "1) first it will make the root node considiring the information gain by selecting the best feature for the root node \n",
    "2) then it split it 2 root node then further agian again until  we have the pure datasplit.\n",
    "3) it works as lets suppose we have feature wind speed and dependent varaible rain outocme yes and no so if wind speed less than 2 how many variable less than 2 result will rain and how many result no rain or if greater than 2 how many will result in raining and not raining accoriding to this criteria data is split into nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45811772",
   "metadata": {},
   "source": [
    "### ANS 4\n",
    "geometric intution behind decision tree classification:\n",
    "1) just like in trees have roots and is further splited to make provide strength to the upper part .decision tree classification follows the same process.\n",
    "2) it works as lets suppose we have feature wind speed and dependent varaible rain outocme yes and no so if wind speed less than 2 how many variable less than 2 result will rain and how many result no rain or if greater than 2 how many will result in raining and not raining accoriding to this criteria data is split into nodes until we have the pure split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201dc6b",
   "metadata": {},
   "source": [
    "### ANS 5\n",
    "confusion matrix is used to know the true positive,true negative,false positive,false neagitve it used to evaluate the peformance of the model because confusion matrix is used to find accuracy of the model precsion, recall  and f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a504e",
   "metadata": {},
   "source": [
    "### ANS 6\n",
    "confusion matrix can be used for the calculation of the precision, recall and f1 score \n",
    "1) precision formula is tp/fn+tp\n",
    "2) recall formula is tp/tp+fn\n",
    "3) F1 score is the harmonic mean of the precision and recall.\n",
    "which can be calculated via confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77111cf7",
   "metadata": {},
   "source": [
    "### ANS 7\n",
    "using appropriate evaluation metric for classification problem can be dony by :\n",
    "1) when actual false positive is important in model then we use precision.\n",
    "2) recall is used when false negative is important in our model.\n",
    "3) accuracy is used when our dataset is balanced.\n",
    "4) when both false negative and false positive is important then using f1 score is a good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfbcd48",
   "metadata": {},
   "source": [
    "### ANS 9\n",
    "recall is important when false negative is consideration is important.\n",
    "for example:lets suppose our model is to predict patient is diabatic or not\n",
    "1) our model predict all the positive value with the actual positve value. \n",
    "2) our model predict the false value with the actual false value.\n",
    "3) our model prdict positive but the actual value is false.\n",
    "4) our model predict false but the acutal value is positve.\n",
    "****\n",
    "now here we can see our model predict patient is not diabatic but in real case patient is diabatic which can trobulesome so in here we will precision for the actual accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6793d",
   "metadata": {},
   "source": [
    "### ANS 8\n",
    "precision is important when false positive play an important role in the model.lets suppose we have to detect if our mail is spam or not.\n",
    "1) our model predict all the positive value with the actual positve value.\n",
    "2) our model predict the false value with the actual false value.\n",
    "3) our model prdict positive but the actual value is false.\n",
    "4) our model predict false but the acutal value is positve.\n",
    "***\n",
    "here we can see our model predict mail is spam but it is not spam which is fault so here we will use precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd863a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
