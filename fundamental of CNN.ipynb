{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05506ef7-7396-43e9-ac77-8d5369755b49",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Difference between object detection and object classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165c997-60aa-4a7d-901a-cba21b9a3266",
   "metadata": {},
   "source": [
    "### object classification \n",
    "1) it involves marking a whole image as label.\n",
    "2) its main object is to determine images without specifying their location \n",
    "3) it is usually a single-label classification where label is encoded to the most likely class.\n",
    "***\n",
    "### Object classification:\n",
    "1) it involves what object are present in image and also specifying thier location.\n",
    "2) it is a multi class classifcation task \n",
    "3) it function is to find building boxes where the object is present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3577b7-837c-47a4-8203-ac48db92d2d2",
   "metadata": {},
   "source": [
    "# Scenarios where object detection is used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9fd8e6-a9c6-4ac2-9109-c4b534fd36fb",
   "metadata": {},
   "source": [
    "1) it is used on sites for human verification.It asks multiple image classfication task to identify the one main class.\n",
    "2) it can be used for marking attendance via camera. if multiple people get into the image of camera it can identify the main person.\n",
    "3) detecting fake car plate on a image of multiple car. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33de94-d394-49fc-9245-8f4ac06aa9d6",
   "metadata": {},
   "source": [
    "# Image data as Structured Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73488da-ce8f-4327-80f4-d3730848ed7e",
   "metadata": {},
   "source": [
    "Image data can be considered as structured data when:\n",
    "1) when we have extracted meaningful feature from image for example Cnn.\n",
    "2) making the test data to categorical form for better classifcation.\n",
    "3) by detecting object which part of the image have images and providing its cordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a4f0e-578b-4713-93a5-ca65ffc0e25a",
   "metadata": {},
   "source": [
    "# Explaining information in an image for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd058d-c2f9-4417-b45d-a6c1482d9a6c",
   "metadata": {},
   "source": [
    "CNN: it stands for convulational neural network. It is mainly used to extract the important infroamtion from the image to reduce the number of parameter in flatten layer.\n",
    "1) it adds weights in th pooling or in feature extraction which is used to take important feature of the image and also uses various layer of differnt kernel sizes or strides which reduces the dimension of the image making less parameter to be trained.\n",
    "\n",
    "***\n",
    "key components of cnn:\n",
    "1) padding \n",
    "2) pooling \n",
    "3) strides \n",
    "4) kernel_size\n",
    "5) filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f343ec9-faa8-4faa-b8ae-0b00458e6071",
   "metadata": {},
   "source": [
    "# Flattening images for ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a32903-d298-4e86-baa4-da1fe26588ef",
   "metadata": {},
   "source": [
    "it is not recomended to directly flatten the image because of two main reasons:\n",
    "1) feature of 2D images are lost when it is flattened to 1D vector input. Before feeding an image to the hidden layer we must preserve the important feature of 2D image.\n",
    "2) images of higher dimension can result in training soo many parameter leading to very high computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1115ca-c98b-4a8f-844e-bf387fca7f44",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Applying CNN to the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149c4a9-f4a1-41df-a03a-7f6c9a028abb",
   "metadata": {},
   "source": [
    "it is necessary to apply cnn to the mnist dataset because it is an 2d image and before procedding it to aflatten layer we must extract the important feature of the images. It is a (28,28,1) image meaning it a grey scale image and have dimension of 28*28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b547268-8479-48cc-ad2c-fa9168b9cb3c",
   "metadata": {},
   "source": [
    "# Extractig Faturs at Local Space: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6944eed-f30a-45c9-a9eb-c3e9c70ca347",
   "metadata": {},
   "source": [
    "It is important to extract features from an image at the local level rather than considering th whole because of following reasons:\n",
    "1) we may not be able to apply strides concept properly.\n",
    "2) it may not be able extract important feature.\n",
    "3) different filter are made for different puprose some give importance to edges some to middle to extract the imporant feature. \n",
    "4) padding will disrput the information of the whole image.\n",
    "5) it can be computational expensive.\n",
    "6) by applying filter on whole image our model may not abel to categorize properly or may not non-linearity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a99d2d-3996-4682-a7af-4380870e0e23",
   "metadata": {},
   "source": [
    "\n",
    "7) it may not be able to localize important feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d68d0b-345e-4f28-bc5a-e7d0052558a0",
   "metadata": {},
   "source": [
    "# Importance of Covolutio ad Max Poolig:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ebbe1d-3e2d-4800-9de0-b16260e3e33b",
   "metadata": {},
   "source": [
    "Convulation is mainly used to minimize the paremeter number before applying the neural layer. Max pooling is used to downsampling the feature dimension it only takes the highest value from the matrix. Max pooling is mainly used for downsampling of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777d7ab-f70e-447e-98f1-9973fbe56cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
