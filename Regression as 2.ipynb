{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091cea0d-1fc6-4c95-a238-b10198ed9018",
   "metadata": {},
   "source": [
    "### ANS 1\n",
    "R-squared in linear regression is used to compute the accuracy of the model it gives us the percentage of the model accuracy.\n",
    "***\n",
    "formula to calculate the R-squared:\n",
    "R^2=1-ssr/sst\n",
    "R^2=accuracy of the model \n",
    "ssr=sum of squares of residual \n",
    "sst=total sum of squares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a67d102-6ed2-44e1-af65-f9af9e9ef2ce",
   "metadata": {},
   "source": [
    "### ANS 2\n",
    "adjusted r-squared compute the accuracy of the model r-squared accuracy always increasese even if the feature is not much significant but in adjusted r-squared if the feature is not significant then the accuracy decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8aa74b-0516-4ae8-9863-80068b31dbdb",
   "metadata": {},
   "source": [
    "### ANS 3\n",
    "it is preferred to use adjusted r-squared:\n",
    "1) it penalizes the inclusion of unecessary predictors by adjusting the number for the number of predictors in the model\n",
    "2) adjusted r-squared can help you detect overfitting by decreasing irrelevant predictors or noise to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f95951-ef4f-4229-a43c-b8aea5b2a460",
   "metadata": {},
   "source": [
    "### ANS 4\n",
    "1) RMSE:stands for Root Mean square Error it is a cost function which is used to measure the error between the predicted values and the actual value. it is also not robust to outleirs.\n",
    "2) MSE: It stands for Mean squared Error it also measure the error between the predicted value and the actual value. it is not robust to outliers.\n",
    "3) MAE: it stands for Mean absolute error.it also measure the error between the predicted value and the actual value.it is robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80ae9b-c007-4122-a139-45c851b09fb6",
   "metadata": {},
   "source": [
    "### ANS 5\n",
    "advantages of MSE:\n",
    "1)  Equation is differentiable \n",
    "2) it has only one local or global minima. \n",
    "***\n",
    "advantages of MAE:\n",
    "1) It is robust to ouliers\n",
    "2) it will be in the same unit\n",
    "***\n",
    "advantages of RMSE:\n",
    "1) it is of same unit\n",
    "2) Differentiable \n",
    "***\n",
    "Disadvantages of MSE:\n",
    "1) it is not robust to outliers.\n",
    "2) it is not in the same unit.\n",
    "***\n",
    "Disadvantages of MAE:\n",
    "1) converge takes more time as compared to mse.\n",
    "***\n",
    "Disadvantages of RMSE:\n",
    "1) It is also not robust to error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f6990-2c15-492f-a7ce-f1046745bd03",
   "metadata": {},
   "source": [
    "### ANS 6\n",
    "Lasso regularization uses different cost function as compared to the linear regression it is specifically used for feature selection feature which are not important gets 0 coefficient. it differe from ridge regulariztion because ridge model is used when our model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d4239-e359-4256-88d7-b52a6b769765",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ANS 7\n",
    "regularized linear models helps in model overfitting by using ridge regression we can reduce overfitting. ridge regression add some value value to cost fucntion to increase so that it can perform better on test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169323ac-9dcc-4d17-bd18-f389a9419ecf",
   "metadata": {},
   "source": [
    "### ANS 8\n",
    "1) Linearity: it is limited to linear relationship \n",
    "2) hyperparameter tunning can be complex \n",
    "3) limited to model complexity it cannot deal with complex data \n",
    "4) lasso regression is used for feature selection where it will make coefficient zero but because of limited domain knowldege it can exclude relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82139309-c3bf-49a6-ba46-470aa7b3bf93",
   "metadata": {},
   "source": [
    "### ANS 9\n",
    "Model A RMSE=10 \n",
    "Model B MAE=8 \n",
    "we will chose mae because its average distance between actual value and predicted value is less making accurate prediction on average. higher value of RMSE also indicates that there is a outlier.\n",
    "***\n",
    "Limitation of MAE:\n",
    "1) convergence usually takes more time\n",
    "***\n",
    "Limitation of RMSE:\n",
    "1) Not robust to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e72fec-d5e7-422e-8292-5b8388bb77af",
   "metadata": {},
   "source": [
    "### ANS 10\n",
    "we will chose lasso regularization beacuse its lambda value is 0.5 which is significantly high so it may make coef zero of some feature providing focus on main feature which is useful for the model. note is totally dependent on the r squared to check efficieny of the model whosoever the model r squared value is high that model is perforaming better.\n",
    "***\n",
    "TRADE OFF:\n",
    "1) it wise to use ridge regression to reduce the overfitting in the model.\n",
    "2) lasso is generally preffered when we want to do feature selection because it makes coefficient zero. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d315d27-5963-4426-8eff-a19de9db4fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
